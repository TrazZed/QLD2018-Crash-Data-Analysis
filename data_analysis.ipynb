{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import plotly.express as px\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"visualisations\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "crash_facts = pd.read_excel(\"data/crash_fact_table.xlsx\")\n",
    "date_dimensions = pd.read_excel(\"data/date_dimension.xlsx\")\n",
    "location_dimensions = pd.read_excel(\"data/location_dimension.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data integrity validation\n",
    "\n",
    "# If duplicates exist, remove them\n",
    "crash_facts = crash_facts.drop_duplicates()\n",
    "date_dimensions = date_dimensions.drop_duplicates()\n",
    "location_dimensions = location_dimensions.drop_duplicates()\n",
    "\n",
    "# Check fields \n",
    "print(crash_facts['Crash_Speed_Limit'].unique())\n",
    "print(crash_facts['Crash_Severity'].unique())\n",
    "\n",
    "# Type in a data entry for Medical Treatement (spelt with an extra full stop). Fixing\n",
    "crash_facts['Crash_Severity'] = crash_facts['Crash_Severity'].str.replace('Medical treatment.', 'Medical treatment')\n",
    "print(crash_facts['Crash_Severity'].unique())\n",
    "\n",
    "# Re-order speeds to correct order\n",
    "speed_order = ['0 - 50 km/h', '60 km/h', '70 km/h', '80 - 90 km/h', '100 - 110 km/h']\n",
    "crash_facts['Crash_Speed_Limit'] = pd.Categorical(crash_facts['Crash_Speed_Limit'], categories=speed_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the frequency of crashes in each speed zone (note that this doesnt account for the fact that more people drive in lower speed limit zones)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(y=crash_facts[\"Crash_Speed_Limit\"], palette=\"viridis\")\n",
    "plt.xlabel(\"Count of Crashes\")\n",
    "plt.ylabel(\"Speed Limit\")\n",
    "plt.title(\"Distribution of Crashes by Speed Limit\")\n",
    "plt.savefig(\"visualisations/crash_frequency.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table for stacked bar chart\n",
    "severity_counts = crash_facts.pivot_table(index=\"Crash_Speed_Limit\", columns=\"Crash_Severity\", aggfunc=\"size\", fill_value=0)\n",
    "\n",
    "# Plot\n",
    "severity_counts.plot(kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"viridis\")\n",
    "plt.xlabel(\"Speed Limit\")\n",
    "plt.ylabel(\"Number of Crashes\")\n",
    "plt.title(\"Crash Severity by Speed Limit\")\n",
    "plt.legend(title=\"Crash Severity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"visualisations/severity_speed_bar.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# For the heatmap, normalise the data to remove bias of areas with more total crashes due to more traffic.\n",
    "heatmap_data = severity_counts.div(severity_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".2%\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Speed Limit\")\n",
    "plt.title(\"Heatmap of Crash Severity by Speed Limit\")\n",
    "plt.savefig(\"visualisations/severity_speed_heat.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between Crash Type and Crash Severity. For example, what types of crashes produce the most or least severe outcomes.\n",
    "# Create pivot table for stacked bar chart\n",
    "severity_counts = crash_facts.pivot_table(index=\"Crash_Type\", columns=\"Crash_Severity\", aggfunc=\"size\", fill_value=0)\n",
    "\n",
    "# Plot\n",
    "severity_counts.plot(kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"viridis\")\n",
    "plt.xlabel(\"Crash Type\")\n",
    "plt.ylabel(\"Number of Crashes\")\n",
    "plt.title(\"Crash Severity by Crash Type\")\n",
    "plt.legend(title=\"Crash Severity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"visualisations/severity_type_bar.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# For the heatmap, normalise the data to remove bias of areas with more total crashes due to more traffic.\n",
    "heatmap_data = severity_counts.div(severity_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".2%\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.xlabel(\"Crash Severity\")\n",
    "plt.ylabel(\"Crash Type\")\n",
    "plt.title(\"Heatmap of Crash Severity by Crash Type\")\n",
    "plt.savefig(\"visualisations/severity_type_heat.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of crashes (and their Crash Severity) for each month of 2018.\n",
    "\n",
    "# Merge the two dataframes on 'date_key' to get year and month\n",
    "merged_data = crash_facts.merge(date_dimensions[['Date_Key', 'Crash_Year', 'Crash_Month']], on='Date_Key', how='left')\n",
    "\n",
    "# Filter data for 2018\n",
    "merged_data_2018 = merged_data[merged_data['Crash_Year'] == 2018]\n",
    "\n",
    "# Group by 'year', 'month' and 'Crash_Severity', and count the number of crashes\n",
    "monthly_crashes = merged_data_2018.groupby(['Crash_Year', 'Crash_Month', 'Crash_Severity']).size().reset_index(name='crash_count')\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "monthly_crashes['Crash_Month'] = pd.Categorical(monthly_crashes['Crash_Month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Create a pivot table to get the crash count by month and severity\n",
    "monthly_crashes_pivot = monthly_crashes.pivot_table(index=['Crash_Month'], columns='Crash_Severity', values='crash_count', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "monthly_crashes_pivot.plot(kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"viridis\")\n",
    "\n",
    "plt.title('Monthly Crash Severity in 2018')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Crash Severity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/monthly_crash_severity.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets on 'Location_Key'\n",
    "merged_data = crash_facts.merge(location_dimensions[['Location_Key', 'Loc_Suburb']], on='Location_Key', how='left')\n",
    "\n",
    "# Group by 'Loc_Suburb' and 'Crash_Severity' to count crashes by severity for each suburb\n",
    "severity_by_suburb = merged_data.groupby(['Loc_Suburb', 'Crash_Severity']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate total number of crashes for each suburb\n",
    "suburb_total_crashes = merged_data['Loc_Suburb'].value_counts()\n",
    "\n",
    "# Add the total crashes column to the severity DataFrame\n",
    "severity_by_suburb['Total_Crashes'] = suburb_total_crashes\n",
    "\n",
    "# Sort the suburbs by total crashes in descending order and get the top 10\n",
    "top_10_suburbs = severity_by_suburb.sort_values(by='Total_Crashes', ascending=False).head(10).reset_index()\n",
    "\n",
    "# Print the top 10 suburbs with severity breakdown and total crashes\n",
    "print(top_10_suburbs)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "ax = top_10_suburbs.drop(columns='Total_Crashes').plot(kind='bar', stacked=True, figsize=(12, 6), colormap=\"viridis\")\n",
    "\n",
    "# Set x-axis labels to the 'Loc_Suburb' column\n",
    "ax.set_xticklabels(top_10_suburbs['Loc_Suburb'], rotation=45)\n",
    "\n",
    "plt.xlabel(\"Suburb\")\n",
    "plt.ylabel(\"Number of Crashes\")\n",
    "plt.title(\"Top 10 Suburbs with the Most Crashes by Severity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Crash Severity\")\n",
    "plt.savefig('visualisations/top10_suburbs_barchart.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geospatial heat map visulisation for suburbs\n",
    "merged_data = crash_facts.merge(location_dimensions[['Location_Key', 'Crash_Longitude_GDA94', 'Crash_Latitude_GDA94']], on='Location_Key', how='left')\n",
    "\n",
    "# Create the density map\n",
    "fig = px.density_map(merged_data, \n",
    "                        lat='Crash_Latitude_GDA94', \n",
    "                        lon='Crash_Longitude_GDA94', \n",
    "                        color_continuous_scale=\"Viridis\",\n",
    "                        title=\"Geographic Heatmap of Crashes\")\n",
    "# Adjust map appearance\n",
    "fig.update_layout(\n",
    "    width=800,  \n",
    "    height=800, \n",
    ")\n",
    "fig.update_traces(\n",
    "    radius=8,\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
